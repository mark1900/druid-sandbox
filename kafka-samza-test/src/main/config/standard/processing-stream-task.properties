
# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=processing-stream-task

# YARN
#yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-dist.tar.gz
yarn.package.path=hdfs://${hadoop.hostname}:9000/kafka-samza-test/${project.artifactId}-${pom.version}-dist.tar.gz

# Task
task.class=test.task.ProcessingStreamTask
task.inputs=kafka.kafka_samza_test_phase_01
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
# Normally, this would be 3, but we have only one broker.
task.checkpoint.replication.factor=1

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory

# Serializers
#serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
#systems.kafka.samza.msg.serde=json
systems.kafka.samza.msg.serde=string
systems.kafka.streams.metrics.samza.msg.serde=metrics
systems.kafka.consumer.zookeeper.connect=${zookeeper.hostname}:2181/
systems.kafka.consumer.auto.offset.reset=largest
systems.kafka.producer.bootstrap.servers=${kafka.hostname}:9092
